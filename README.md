# CodeWhiz.AI ğŸ§™â€â™€ï¸ğŸ’¬
â€œTalk to a true algorithm whiz!!â€

# ğŸ‘©ğŸ»â€ğŸ«ğŸ“šğŸ–³ **DSA Tutor Chatbot**

> *A local-first Data Structures and Algorithms (DSA) tutor chatbot that runs entirely on your machine â€” no cloud, just power! âš¡*

---

## ğŸ“š Overview

The **DSA Tutor Chatbot** is designed to help users learn **Data Structures and Algorithms** through **interactive conversations**, **quizzes**, and **live C++ code execution**.
It leverages a **Retrieval-Augmented Generation (RAG)** architecture powered by TinyLlama ğŸ¦™ to provide accurate and contextually relevant information on DSA concepts.

---

## ğŸš€ Features

ğŸ”¹ **Interactive Learning** â€“ Ask questions about any DSA topic and get detailed explanations
ğŸ§  **Quiz System** â€“ Test your knowledge with quizzes on various DSA topics
ğŸ’» **Code Execution** â€“ Run and test C++ code snippets directly in the chat
ğŸ“œ **Code Explanation** â€“ Get clear explanations of C++ code to understand algorithms better
ğŸ“Š **Progress Tracking** â€“ Monitor your learning journey across different DSA topics

---

## ğŸ§© Architecture

The **DSA Tutor Chatbot** is built with a **modular architecture**, including:

1. ğŸ—‚ï¸ **Knowledge Base Indexer** â€“ Converts JSON files (`algorithms.json`, `concepts.json`, `problems.json`) into a **vector database** for semantic retrieval
2. ğŸ§  **LLM Module** â€“ Uses open-source models (like **TinyLlama**) for generating responses
3. ğŸ“ **Quiz Manager** â€“ Handles quiz creation and scoring
4. âš™ï¸ **C++ Executor** â€“ Compiles and runs C++ code in a **sandboxed environment**
5. ğŸ§¾ **User Data Store** â€“ Tracks user progress using **SQLite**
6. ğŸ’¬ **Chat Engine** â€“ Connects everything and responds to user input

---

## ğŸ› ï¸ Installation

### ğŸ“Œ Prerequisites

* ğŸ Python **3.8+**
* ğŸ› ï¸ C++ compiler (**g++** or **clang**)
* âš¡ CUDA-compatible GPU *(optional, for faster LLM inference)*

---

### ğŸ“¥ Setup

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/DSA_BOT.git
   cd DSA_BOT
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Download the LLM model**

   ```bash
   mkdir -p models
   # Download TinyLlama model
   wget -O models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
   ```

4. **Initialize the knowledge base**

   ```bash
   python -c "from src.knowledge_indexer import KnowledgeIndexer; KnowledgeIndexer(knowledge_base_dir='data/knowledge_base', db_directory='chroma_db').index_knowledge_base()"
   ```

---

## ğŸ’¬ Usage

### â–¶ï¸ Running the Chatbot

```bash
python main.py
```

Customize it with your own model or knowledge base:

```bash
python main.py --model models/your-model-name.gguf --knowledge-base path/to/knowledge_base
```

---

### ğŸ§‘â€ğŸ« Interacting with the Chatbot

1. **Ask questions** ğŸ§ 

   ```text
   What is the time complexity of quicksort?
   ```

2. **Take quizzes** ğŸ“

   ```text
   quiz sorting algorithms
   ```

3. **Run code** ğŸ’»

   ````text
   run
   ```cpp
   #include <iostream>

   int main() {
       std::cout << "Hello, World!" << std::endl;
       return 0;
   }
   ````

4. **Get explanations** ğŸ§¾

   ```text
   explain binary search
   ```

5. **Check progress** ğŸ“Š

   ```text
   progress
   ```

6. **Get help** â“

   ```text
   help
   ```

7. **Exit chatbot** ğŸ›‘

   ```text
   exit
   ```

---

## ğŸ—‚ï¸ Project Structure

```
DSA_BOT/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ knowledge_base/
â”‚       â”œâ”€â”€ algorithms.json
â”‚       â”œâ”€â”€ concepts.json
â”‚       â””â”€â”€ problems.json
â”œâ”€â”€ models/
â”‚   â””â”€â”€ tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat_engine.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ cpp_executor/
â”‚   â”‚   â””â”€â”€ executor.py
â”‚   â”œâ”€â”€ knowledge_indexer.py
â”‚   â”œâ”€â”€ llm_module.py
â”‚   â”œâ”€â”€ quiz_manager.py
â”‚   â””â”€â”€ user_data_store.py
â”œâ”€â”€ chroma_db/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ user_data.db
```

---

## ğŸ¨ Customization

### â• Adding New Knowledge

Expand the knowledge base by editing or adding new JSON files inside the `data/knowledge_base` directory:

* `algorithms.json` â€“ Info about various algorithms
* `concepts.json` â€“ Explanations of DSA topics
* `problems.json` â€“ Practice problems and solutions

Then reindex the knowledge base:

```bash
python -c "from src.knowledge_indexer import KnowledgeIndexer; KnowledgeIndexer(knowledge_base_dir='data/knowledge_base', db_directory='chroma_db').index_knowledge_base()"
```

---

### ğŸ”„ Using Different LLM Models

You can use **any GGUF-compatible model**!
Just download the model to the `models/` directory and start the chatbot like this:

```bash
python main.py --model models/your-model-name.gguf
```

---

## âš ï¸ Limitations

* ğŸ§  Response quality depends on the selected LLM
* ğŸ”’ Code execution is sandboxed and limited to standard libraries
* ğŸ§® Requires sufficient system memory (minimum **4GB RAM** recommended)

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€“ see the `LICENSE` file for full details.

---

## ğŸ™ Acknowledgments

* ğŸ¤– Uses the **TinyLlama** model for intelligent chat responses
* ğŸ’¾ Vector database powered by **ChromaDB**
* ğŸ” **Sentence Transformers** used for semantic search

---

Let the learning begin! ğŸŒŸğŸ‘¨â€ğŸ’»ğŸ‘©â€ğŸ’»
